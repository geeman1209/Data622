---
title: "HMK3 | Loan Prediction"
author: "Abdellah AitElmouden | Gabriel Abreu |  Jered Ataky"
date: "10/13/2021"
output: html_document
---

```{r setup, include=FALSE}
library(GGally)
library(caret)
library(mice)
library(tidyverse)
library(DataExplorer)
library(MASS)
library(naniar)
knitr::opts_chunk$set(echo = TRUE)
```

## Problem Statement

Company wants to automate the loan eligibility process (real time) based on customer detail provided while filling online application form. These details are Gender, Marital Status, Education, Number of Dependents, Income, Loan Amount, Credit History and others. To automate this process, they have given a problem to identify the customers' segments, those are eligible for loan amount so that they can specifically target these customers. Here they have provided a partial data set.


### Data Exploration 

The first step is to look at the data we're working with. Realistically, most of the data we will get, even from the government, can have errors, and it's important to identify these errors before spending time analyzing the data. Normally, we must answer the following questions:

- Do we find something wrong in the data?
- Are there ambiguous variables in the dataset?
- Are there variables that should be fixed or removed?

Let's start by reading the data using the function read.csv() and show the first part of the dataset:

```{r, echo=FALSE}
loan_data <- read.csv("Loan_approval.csv")
```

The first row in the dataset defines the column header. Each of these headers is described in the below table. 

```{r}
glimpse(loan_data)
```


Now, let's have a closer look at the missing data:

```{r}
plot_missing(loan_data)
```


The variables Loan_Amount_Term and LoanAmount have a relatively small amount of missing variables which can be imputed. There is an acceptable amount of missing rows for the variable Credit_History. Loan_ID is a prime candidate to eliminate from the data, since there are 614 unique values that are not going to provide additional value to the models we will build. 


```{r}
gg_miss_upset(loan_data)
```
Now, we will run the skim function to have a quick look on the stats:

```{r}
skimr::skim(loan_data)
```
The mean of Credit_history variable is 0.8422. That's weird knowing that this variable has value of 1 for customers who have credit history and 0 otherwise.

There are blank fields in Gender, Married, Dependents and Self_Employed. Also There are NAs in LoanAmount, Loan_Amount_term and Credit_History.

### Distribution of the data

#### Numerical Variables

Now, it's the time to give a look at the distribution of the data. We will start with the numerical variables: Loan Amount and ApplicantIncome:
Below are the histograms and the boxplots of the loan amount and the applicant income variables:

```{r}
par(mfrow=c(2,2))
hist(loan_data$LoanAmount, 
     main="Histogram for LoanAmount", 
     xlab="Loan Amount", 
     border="blue", 
     col="blue",
     las=1, 
     breaks=20, prob = TRUE)
boxplot(loan_data$LoanAmount, col='blue',xlab = 'LoanAmount', main = 'Box Plot for Loan Amount')
hist(training$ApplicantIncome, 
     main="Histogram for Applicant Income", 
     xlab="Income", 
     border="blue", 
     col="green",
     las=1, 
     breaks=50, prob = TRUE)
#lines(density(training$ApplicantIncome), col='black', lwd=3)
boxplot(loan_data$ApplicantIncome, col='maroon',xlab = 'ApplicantIncome', main = 'Box Plot for Applicant Income')
```
Here we notice that there are few extreme values in both variables. Let's also examine if the applicant' loan amounts distribution is affected by their educational level:

```{r}
library(ggplot2)
data(loan_data, package="lattice")
ggplot(data=loan_data, aes(x=LoanAmount, fill=Education)) +
  geom_density() +
  facet_grid(Education~.)
```

From the graph we can notice that graduates have more outliers and their loan amount distribution is wider.

#### Categorical Variables

let's take a look at the categorical variables in the dataset:

```{r}
par(mfrow=c(2,3))
counts <- table(loan_data$Loan_Status, loan_data$Gender)
barplot(counts, main="Loan Status by Gender",
        xlab="Gender", col=c("darkgrey","maroon"),
        legend = rownames(counts))
counts2 <- table(loan_data$Loan_Status, loan_data$Education)
barplot(counts2, main="Loan Status by Education",
        xlab="Education", col=c("darkgrey","maroon"),
        legend = rownames(counts2))
counts3 <- table(loan_data$Loan_Status, loan_data$Married)
barplot(counts3, main="Loan Status by Married",
        xlab="Married", col=c("darkgrey","maroon"),
        legend = rownames(counts3))
counts4 <- table(loan_data$Loan_Status, loan_data$Self_Employed)
barplot(counts4, main="Loan Status by Self Employed",
        xlab="Self_Employed", col=c("darkgrey","maroon"),
        legend = rownames(counts4))
counts5 <- table(loan_data$Loan_Status, loan_data$Property_Area)
barplot(counts5, main="Loan Status by Property_Area",
        xlab="Property_Area", col=c("darkgrey","maroon"),
        legend = rownames(counts5))
counts6 <- table(loan_data$Loan_Status, loan_data$Credit_History)
barplot(counts6, main="Loan Status by Credit_History",
        xlab="Credit_History", col=c("darkgrey","maroon"),
        legend = rownames(counts5))
```
If we look at the Gender graph, we note that males have more records and more than half of the applicants' applications have been approved. There are less female applicants but still more than half of their applications have been approved. We look at the other charts with the same eye to evaluate how each category performed in regards to the approval of the loan applications.

Now let's take a look at the categorical variables in relation to the target variable Loan_Status.

```{r, echo=FALSE, message=FALSE, warning=FALSE, fig.dim=c(4,3), fig}
loan_data%>%ggplot(aes(Gender,fill=Loan_Status))+geom_bar()
loan_data%>%ggplot(aes(Married,fill=Loan_Status))+geom_bar()
loan_data%>%ggplot(aes(Dependents,fill=Loan_Status))+geom_bar()
loan_data%>%ggplot(aes(Education, fill=Loan_Status)) + geom_bar()
loan_data%>%ggplot(aes(Self_Employed,fill=Loan_Status))+geom_bar()
loan_data%>%ggplot(aes(Property_Area,fill=Loan_Status))+geom_bar()
```

```{r, echo=FALSE, message=FALSE, warning=FALSE, fig2.dim=c(4,4), fig2}
loan_data %>% dplyr::select(ApplicantIncome, CoapplicantIncome, LoanAmount, Loan_Amount_Term, Credit_History, Loan_Status) %>% ggpairs()
```

### Data Imputation / Variable Selection / Data Partition

There are low levels of correlation among the variables but the variables are clearly skewed and need transformation, especially for LDA. LDA assumes normality, homoscedasticity, low levels of multicollinearity, and independence. 



First eliminate Loan_ID from the data series. 
```{r}
loan_data2 <- loan_data %>% dplyr::select(-Loan_ID)
```

Impute the data using predictive mean matching for continuous values.

```{r, echo=FALSE, message=FALSE, warning=FALSE}
imp_value <- mice(loan_data2, m = 3, method = "pmm")  
```

```{r}
imp_data <- complete(imp_value)
```

```{r}
imp_data$Credit_History <- as.factor(imp_data$Credit_History)
```

```{r}
preprocess_loan <- preProcess(imp_data, method = c("BoxCox"))
```

```{r}
transformed <- predict(preprocess_loan, imp_data)
```

```{r, echo=FALSE, message=FALSE, warning=FALSE}
transformed %>% dplyr::select(ApplicantIncome, CoapplicantIncome, LoanAmount, Loan_Amount_Term, Credit_History, Loan_Status) %>% ggpairs()
```

The BoxCox transformation made a difference in the skewness of ApplicantIncome, LoanAmount, and Loan_Amount_Term. coapplicantincome is still right-tailed skewed. The variable Credit History works better as a factor since it is a binary variable. 


we will also use the CART imputation method. If we know that the values for a measurement fall in a certain range, we can fill in empty values with the average of that measurement. 
```{r}
training$Income <- training$ApplicantIncome + training$CoapplicantIncome
training$ApplicantIncome <- NULL
training$CoapplicantIncome <- NULL

training$LogIncome <- log(training$Income)
par(mfrow=c(1,2))
hist(training$LogIncome, 
     main="Histogram for Applicant Income", 
     xlab="Income", 
     border="blue", 
     col="maroon",
     las=1, 
     breaks=50, prob = TRUE)
lines(density(training$LogIncome), col='black', lwd=3)
boxplot(training$LogIncome, col='maroon',xlab = 'Income', main = 'Box Plot for Applicant Income')
```


### Building Predictive Models

Now it's the time to make the next big step in our analysis which is splitting the data into training and test sets.
qssss
A training set is the subset of the data that we use to train our models but the test set is a random subset of the data which are derived from the training set. We will use the test set to validate our models as un-foreseen data. 

In a sparse data like ours, it's easy to overfit the data. Overfit in simple terms means that the model will learn the training set that it won't be able to handle most of the cases it has never seen before. Therefore, we are going to score the data using our test set. Once we split the data, we will treat the testing set like it no longer exists. Let's split the data:


```{r}

partition <- reateDataPartition(transformed$Loan_Status, p = 0.8, list=FALSE)

training <- transformed[partition,]
testing <- transformed[-partition,]
```

It's time to treat the extreme values. Looking at the LoanAmount variable, we guess that extreme values are possible as some customers, for some reason, may want to apply for higher loan amounts. We will perform the log transformation to normalize the data:

```{r}
training$LogLoanAmount <- log(training$LoanAmount)
training$LogIncome <- log(tr$Income)
par(mfrow=c(1,2))
hist(training$LogLoanAmount, 
     main="Histogram for Loan Amount", 
     xlab="Loan Amount", 
     border="blue", 
     col="maroon",
     las=1, 
     breaks=20, prob = TRUE)
lines(density(training$LogLoanAmount), col='black', lwd=3)
boxplot(training$LogLoanAmount, col='maroon',xlab = 'Income', main = 'Box Plot for Applicant Income')
```


### LDA 

Fit the model to the data
```{r}
ldaModel <- lda(Loan_Status ~., data = training)
```

```{r}
ldaModel
```
```{r}
predicted <- predict(ldaModel, testing)
```

```{r}
names(predicted)
```

```{r}
mean(predicted$class==testing$Loan_Status)
```

The model correctly predicted the Loan_Status for 85% of the observations in the test data set. 


Visualizing the results 
```{r}
ldahist(data=predicted$x , g= training$Loan_Status)
```

There is overlap, which isn't good for LDA. The model has an accuracy of 85.25% but given the overlap perhaps Linear Discrimnant Analysis is not the optimal model. 


```{r}
confusionMatrix(testing$Loan_Status, predicted$class)
```

### KNN


### Decision Tree

Decision trees create a set of binary splits on the predictor variables in order to create a tree that can be used to classify new observations into one of two groups. Here, we will be using classical trees. The algorithm of this model is the following:

- Choose the predictor variable that best splits the data into two groups;
- Separate the data into these two groups;
- Repeat these steps until a subgroup contains fewer than a minimum number of observations;
  
To classify a case, run it down the tree to a terminal node, and assign it the model outcome value     assigned in the previous step.

```{r}
library(rpart)
# grow tree 
dtree <- rpart(Loan_Status ~ Credit_History+Education+Self_Employed+Property_Area+LogLoanAmount+
                 LogIncome,method="class", data=training,parms=list(split="information"))
dtree$cptable
plotcp(dtree)
dtree.pruned <- prune(dtree, cp=.02290076)
library(rpart.plot)
prp(dtree.pruned, type = 2, extra = 104,
    fallen.leaves = TRUE, main="Decision Tree")
dtree.pred <- predict(dtree.pruned, training, type="class")
dtree.perf <- table(training$Loan_Status, dtree.pred,
                    dnn=c("Actual", "Predicted"))
dtree.perf
```


### Random Forest 


### Model Performance 



Sources:

https://machinelearningmastery.com/pre-process-your-dataset-in-r/
https://www.r-bloggers.com/2021/05/linear-discriminant-analysis-in-r/
https://www.statology.org/confusion-matrix-in-r/

