---
title: "HMK3 | Loan Prediction"
author: "Abdellah Ait Elmouden | Gabriel Abreu |  Jered Ataky"
date: "10/13/2021"
output: html_document
---

```{r setup, include=FALSE}
library(GGally)
library(caret)
library(mice)
library(plyr)
library(tidyverse)
library(DataExplorer)
library(MASS)
library(naniar)
library(corrplot)
library(VIM)
knitr::opts_chunk$set(echo = TRUE)
```

## Problem Statement

The two most pressing issues in the banking sector are: 1) How risky is the borrower? 2) Should we lend to the borrower given the risk? Banking processes use manual procedures to determine whether or not a borrower is suitable for a loan based on results. Manual procedures were mostly effective, but they were insufficient when there were a large number of loan applications. At that time, making a decision would take a long time. As a result, the loan prediction machine learning model can be used to assess a customer's loan status and build strategies. In this project we want to automate the loan eligibility process (real time) based on customer detail provided while filling online application form. These details are Gender, Marital Status, Education, Number of Dependents, Income, Loan Amount, Credit History and others. Four machine learning models have been used for the prediction of loan approvals and to automate this process:  LDA algorithm, KNN algorithm, Decision Trees and Random Forests. 

### Data Exploratory

The first step is to explore data we're working with. In this process we'll perform initial investigations on the data to discover patterns,to spot anomalies,to test hypothesis and to check assumptions with the help of summary statistics and graphical representations. 

Let's start by reading the data using the function read.csv() and show the first part of the dataset:

```{r, echo=FALSE}
loan_data <- read.csv("Loan_approval.csv")
```

The first row in the dataset defines the column header. Each of these headers is described in the below table. 
We have 13 features in total out of which we have 12 independent variables and 1 dependent variable.

```{r}
glimpse(loan_data)
```


Now, let's have a closer look at the missing data:

```{r}
plot_missing(loan_data)
```


The variables Loan_Amount_Term and LoanAmount have a relatively small amount of missing variables which can be imputed. There is an acceptable amount of missing rows for the variable Credit_History. Loan_ID is a prime candidate to eliminate from the data, since there are 614 unique values that are not going to provide additional value to the models we will build. 


```{r}
gg_miss_upset(loan_data)
```

### Distribution of the data

Now, we will run the skim function to have a quick look on the stats:

```{r message=FALSE, warning=FALSE}
loan_data[sapply(loan_data, is.character)] <- lapply(loan_data[sapply(loan_data, is.character)], 
                                                           as.factor)
skimr::skim(loan_data)
```

#### Categorical variables

It can also be inferred from the skim output, that in our observed data:

- 81% of loan applicants are male in the training dataset.
- Nearly 65% are married
- About 78% of loan applicants are graduates
- Nearly 85â€“90% loan applicants are self-employed
- The loan has been approved for more than 68% of applicants.

There are blank fields in Gender, Married, Dependents and Self_Employed. Also There are NAs in LoanAmount, Loan_Amount_term and Credit_History.

We'll plot the categorical variables in relation to the target variable Loan_Status.

```{r}
par(mfrow=c(2,3))
counts <- table(loan_data$Loan_Status, loan_data$Gender)
barplot(counts, main="Loan Status by Gender",
        xlab="Gender", col=c("darkgrey","maroon"),
        legend = rownames(counts))
counts2 <- table(loan_data$Loan_Status, loan_data$Education)
barplot(counts2, main="Loan Status by Education",
        xlab="Education", col=c("darkgrey","maroon"),
        legend = rownames(counts2))
counts3 <- table(loan_data$Loan_Status, loan_data$Married)
barplot(counts3, main="Loan Status by Married",
        xlab="Married", col=c("darkgrey","maroon"),
        legend = rownames(counts3))
counts4 <- table(loan_data$Loan_Status, loan_data$Self_Employed)
barplot(counts4, main="Loan Status by Self Employed",
        xlab="Self_Employed", col=c("darkgrey","maroon"),
        legend = rownames(counts4))
counts5 <- table(loan_data$Loan_Status, loan_data$Property_Area)
barplot(counts5, main="Loan Status by Property_Area",
        xlab="Property_Area", col=c("darkgrey","maroon"),
        legend = rownames(counts5))
counts6 <- table(loan_data$Loan_Status, loan_data$Credit_History)
barplot(counts6, main="Loan Status by Credit_History",
        xlab="Credit_History", col=c("darkgrey","maroon"),
        legend = rownames(counts5))
```

Similar to skim output we can see from the graphs that males have more records and more than half of the applicants' applications have been approved. There are less female applicants but still more than half of their applications have been approved. We look at the other charts with the same eye to evaluate how each category performed in regards to the approval of the loan applications.


#### Numerical Variables

Now, it's the time to give a look at the distribution the numerical variables: Loan Amount and ApplicantIncome:

From above skim output we've notice that the mean of Credit_history variable is 0.8422. That's weird knowing that this variable has value of 1 for customers who have credit history and 0 otherwise.

Below are the histograms and the boxplots of the loan amount and the applicant income variables:

```{r}
par(mfrow=c(2,2))
hist(loan_data$LoanAmount, 
     main="Histogram for LoanAmount", 
     xlab="Loan Amount", 
     border="blue", 
     col="blue",
     las=1, 
     breaks=20, prob = TRUE)
boxplot(loan_data$LoanAmount, col='blue',xlab = 'LoanAmount', main = 'Box Plot for Loan Amount')
hist(loan_data$ApplicantIncome, 
     main="Histogram for Applicant Income", 
     xlab="Income", 
     border="blue", 
     col="green",
     las=1, 
     breaks=50, prob = TRUE)
#lines(density(training$ApplicantIncome), col='black', lwd=3)
boxplot(loan_data$ApplicantIncome, col='maroon',xlab = 'ApplicantIncome', main = 'Box Plot for Applicant Income')
```
Here we notice that there are few extreme values in both variables. Let's also examine if the applicant's loan amounts distribution is affected by their educational level:

```{r message=FALSE, warning=FALSE}
library(ggplot2)
data(loan_data, package="lattice")
ggplot(data=loan_data, aes(x=LoanAmount, fill=Education)) +
  geom_density() +
  facet_grid(Education~.)
```

From the graph we can notice that graduates have more outliers and their loan amount distribution is wider.



### Data Preparation

#### Tidying the data

Now that we've identified several errors in the data set, we need to fix them before we continue with our analysis. Let's review the issues:

There are missing values in some variables. Based on the importance of the variables, we will decide   on the method to use.
  
  Looking at the distributions of the data, we noticed that ApplicantIncome and LoanAmount have    outliers. 
  
Fixing outliers can be tricky. It's hard to tell if they were caused by measurement error, errors while recording, or if the outliers are real anomaly. If we decide to remove records, we have to document the reason behind this decision. 

In this data set, we will assume that missing values are systematic because the missing data in certain variables are random throughout the data set. Also, we note that missing values are on both numerical and categorical data, therefore, we will be using the mice package in R. This package helps in imputing missing values with plausible data values. These values are inferred from a distribution that is designed for each missing data point. In the missing data plot above, we note that 0.78 of the data are not missing any information, 0.07 are missing the Credit_History value, and the remaining ones show other missing patterns.

The mice() function takes care of the imputing process:
```{r mice, echo=FALSE}
imputed_Data <- mice(loan_data, m=2, maxit = 2, method = 'cart', seed = 500)
```
It's important to mention that mice stands for multiple imputation by chained equations. The 'm' argument in the function indicates how many rounds of imputation we want to do. For simplicity, I will choose 2. The 'method' argument indicates which of the many methods for imputations we want to use. We chose CART which stands for classification and regression trees. This method work with all variables types, and that's why we chose it. Now let's merge the imputed data into our original dataset. We can do this by using the complete() function:
```{r imp}
loan_data <- complete(imputed_Data,2) #here I chose the second round of data imputation
```
Check missing data again, we note that there is no missing data after the imputation:
```{r imp2}
sapply(loan_data, function(x) sum(is.na(x)))
```
It's time to treat the extreme values. Looking at the LoanAmount variable, we guess that extreme values are possible as some customers, for some reason, may want to apply for higher loan amounts. We will perform the log transformation to normalize the data:
```{r treat, echo=FALSE}
loan_data$LogLoanAmount <- log(loan_data$LoanAmount)
par(mfrow=c(1,2))
hist(loan_data$LogLoanAmount, 
     main="Histogram for Loan Amount", 
     xlab="Loan Amount", 
     border="blue", 
     col="maroon",
     las=1, 
     breaks=20, prob = TRUE)
lines(density(loan_data$LogLoanAmount), col='black', lwd=3)
boxplot(loan_data$LogLoanAmount, col='maroon',xlab = 'Income', main = 'Box Plot for Applicant Income')
```
Now the distribution looks closer to normal and effect of extreme values has significantly subsided.

Coming to ApplicantIncome, it will be a good idea to combine both ApplicantIncome and Co-applicants as total income and then perform log transformation of the combined variable. 

we will use the CART imputation method. If we know that the values for a measurement fall in a certain range, we can fill in empty values with the average of that measurement.

```{r imp3, echo=FALSE}
loan_data$Income <- loan_data$ApplicantIncome + loan_data$CoapplicantIncome
loan_data$ApplicantIncome <- NULL
loan_data$CoapplicantIncome <- NULL

loan_data$LogIncome <- log(loan_data$Income)
par(mfrow=c(1,2))
hist(loan_data$LogIncome, 
     main="Histogram for Applicant Income", 
     xlab="Income", 
     border="blue", 
     col="maroon",
     las=1, 
     breaks=50, prob = TRUE)
lines(density(loan_data$LogIncome), col='black', lwd=3)
boxplot(loan_data$LogIncome, col='maroon',xlab = 'Income', main = 'Box Plot for Applicant Income')
```
We see that the distribution is better and closer to a normal distribution.

#### Correlation and Variable Importance


```{r}
#corrplot(loan_data[sapply(loan_data,is.numeric)], method = "number")
#plot_corr_matrix(loan_data, -1)

loan_data %>% dplyr::select(LogIncome, LogLoanAmount, Loan_Amount_Term, Credit_History, Loan_Status) %>% ggpairs()

```

### Building Predictive Models

There are low levels of correlation among the variables but the variables are clearly skewed and need transformation, especially for LDA. LDA assumes normality, homoscedasticity, low levels of multicollinearity, and independence. 

First eliminate Loan_ID from the data series. 
```{r}
loan_data2 <- loan_data %>% dplyr::select(-Loan_ID)
```

Impute the data using predictive mean matching for continuous values.

```{r, echo=FALSE, message=FALSE, warning=FALSE}
imp_value <- mice(loan_data2, m = 3, method = "pmm")  
```

```{r}
imp_data <- complete(imp_value)
```

```{r}
imp_data$Credit_History <- as.factor(imp_data$Credit_History)
```

```{r}
preprocess_loan <- preProcess(imp_data, method = c("BoxCox"))
```

```{r}
transformed <- predict(preprocess_loan, imp_data)
```

```{r, echo=FALSE, message=FALSE, warning=FALSE}
transformed %>% dplyr::select(LogIncome, LogLoanAmount, Loan_Amount_Term, Credit_History, Loan_Status) %>% ggpairs()
```
The BoxCox transformation made a difference in the skewness of ApplicantIncome, LoanAmount, and Loan_Amount_Term. The variable Credit History works better as a factor since it is a binary variable. 

Now it's the time to make the next big step in our analysis which is splitting the data into training and test sets.

A training set is the subset of the data that we use to train our models but the test set is a random subset of the data which are derived from the training set. We will use the test set to validate our models as un-foreseen data. 

In a sparse data like ours, it's easy to overfit the data. Overfit in simple terms means that the model will learn the training set that it won't be able to handle most of the cases it has never seen before. Therefore, we are going to score the data using our test set. Once we split the data, we will treat the testing set like it no longer exists. Let's split the data:


```{r}
partition <- createDataPartition(transformed$Loan_Status, p = 0.8, list=FALSE)

# transform laon status to binary


training <- transformed[partition,]
testing <- transformed[-partition,]

```

### LDA 

Linear Discriminant Analysis (LDA) is a dimensionality reduction technique. It is a more robust method of performing classifcation especially when compared to logistic regression. LDA is preferred when the there is multi-class classificaiton, classes are well separated and can be used when there are small sample sizes. 

In order to maximize the use of LDA, your data needs to be gaussian and each attribute has the same variance. The LDA model guesses the mean and variance from your data set for each class. LDA makes predictions by utilizing Bayes Theorem to calculate the probability that new values belongs to each class. 

Fit the model to the data using numerical variables. 
```{r}
ldaModel <- lda(Loan_Status ~ LogLoanAmount + LogIncome + Loan_Amount_Term + Credit_History, data = training)
```

```{r}
ldaModel
```
```{r}
predicted <- predict(ldaModel, testing)
```

```{r}
names(predicted)
```

```{r}
mean(predicted$class==testing$Loan_Status)
```

The model correctly predicted the Loan_Status for 82.78% of the observations in the test data set. 


Visualizing the results 
```{r}
ldahist(data=predicted$x , g= training$Loan_Status)
```

```{r}
library(klaR)
partimat(Loan_Status ~ LogLoanAmount + LogIncome + Loan_Amount_Term + Credit_History, data = training, method="lda")
```
There is overlap, which isn't good for LDA. The model has an accuracy of 80.32% but given the overlap perhaps Linear Discrimnant Analysis is not the optimal model. The key principal behind LDA is linear separability, meaning the classes need to be separable by a line in an N dimension Euclidean space. 



```{r}
confusionMatrix(testing$Loan_Status, predicted$class)
```

### KNN

First, let change character variable to numeric


```{r}

cols.num <- c("Gender", "Married", "Dependents", "Education", "Self_Employed","Credit_History", "Property_Area")
training[cols.num] <- sapply(training[cols.num],as.numeric)
sapply(training, class)

testing[cols.num] <- sapply(testing[cols.num],as.numeric)
sapply(testing, class)



training$Loan_Status<-ifelse(training$Loan_Status=="Y",1,0)

testing$Loan_Status<-ifelse(testing$Loan_Status=="Y",1,0)
```


Rule of thumb, we will consider k as square root of the sample. Thus, k = 25
```{r}

library(class)

 #run knn function
 knn_model <- knn(training, testing,cl=training$Loan_Status,k=5)
 

 
 #create confusion matrix
 
 confusionMatrix(table(knn_model ,testing$Loan_Status))

 
```

Optimization: write of function to optimize the accuracy by changing k values

```{r}
i=1
k.optm=1
for (i in 1:28){
 knn_model_optimized <- knn(training, testing, cl=training$Loan_Status, k=i)
 k.optm[i] <- 100 * sum(testing$Loan_Status == knn_model_optimized)/NROW(testing$Loan_Status)
 k=i
 cat(k,'=',k.optm[i],' ')
}

```

Plot accuracy

```{r}

plot(k.optm, type="b", xlab="K- Value",ylab="Accuracy level")

```


We can see that the model reaches the max accuracy at k = 5

Building the new model with k = 5:

```{r}

 #run knn function
 knn_model <- knn(training, testing,cl=training$Loan_Status,k=5)
 

 
 #create confusion matrix
 
 confusionMatrix(table(knn_model ,testing$Loan_Status))

 
```


### Decision Tree

Decision trees create a set of binary splits on the predictor variables in order to create a tree that can be used to classify new observations into one of two groups. Here, we will be using classical trees. The algorithm of this model is the following:

- Choose the predictor variable that best splits the data into two groups;
- Separate the data into these two groups;
- Repeat these steps until a subgroup contains fewer than a minimum number of observations;
  
To classify a case, run it down the tree to a terminal node, and assign it the model outcome value     assigned in the previous step.

```{r mod3}
library(rpart)
# grow tree 
dtree <- rpart(Loan_Status ~ Credit_History+Education+Self_Employed+Property_Area+LogLoanAmount+
                 LogIncome,method="class", data=training,parms=list(split="information"))
dtree$cptable
plotcp(dtree)
dtree.pruned <- prune(dtree, cp=.02290076)
library(rpart.plot)
prp(dtree.pruned, type = 2, extra = 104,
    fallen.leaves = TRUE, main="Decision Tree")
dtree.pred <- predict(dtree.pruned, training, type="class")
dtree.perf <- table(training$Loan_Status, dtree.pred,
                    dnn=c("Actual", "Predicted"))
dtree.perf
```


### Random Forest 


```{r mod4}
library(randomForest) 
training$Loan_Status = factor(training$Loan_Status)
set.seed(42) 
fit.forest <- randomForest(Loan_Status ~ Credit_History+Education+Self_Employed+Property_Area+LogLoanAmount+
                             LogIncome, data=training,
                           
                           importance=TRUE)
fit.forest

importance(fit.forest, type=2)

forest.pred <- predict(fit.forest, testing)
forest.perf <- table(testing$Loan_Status, forest.pred,
                     dnn=c("Actual", "Predicted"))
forest.perf
```


### Model Performance 

Here we are going to load the table with all the metrics for model performance.
(this csv recorded all the metrics we calculated above).

```{r}

perf_table <- read.csv("Models_performance.csv")

```


```{r}

library(kableExtra)
perf_table %>%
  kbl(caption = "Summary of models performance", align = 'c') %>%
  kable_material(c("striped", "hover")) %>%
  row_spec(0, color = "indigo")
```


Sources:

https://machinelearningmastery.com/pre-process-your-dataset-in-r/
https://www.r-bloggers.com/2021/05/linear-discriminant-analysis-in-r/
https://www.statology.org/confusion-matrix-in-r/

